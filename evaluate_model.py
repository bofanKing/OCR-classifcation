import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import models
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from dataset_txt import CustomTxtDataset, transform
from config import CFG, label_map
from PIL import Image
import time  # âœ… æ–°å¢
import matplotlib
matplotlib.use('TkAgg')  # é¿å… PyCharm çš„ backend æŠ¥é”™
import csv  # âœ… åŠ åœ¨æ–‡ä»¶é¡¶éƒ¨çš„ import éƒ¨åˆ†


# âœ… æ„å»ºåå‘æ˜ å°„ï¼šä»ç±»åˆ«å -> ç´¢å¼•ï¼Œå’Œ ç´¢å¼• -> ç±»åˆ«å
name2idx = label_map
idx2name = {v: k for k, v in name2idx.items()}

# âœ… æ¨ç†å‡½æ•°ï¼Œå°è£…ä¸»æµç¨‹
def run_inference():
    # åŠ è½½æ¨¡å‹ç»“æ„
    model = models.resnet50(pretrained=False)
    model.fc = nn.Sequential(
        nn.Linear(model.fc.in_features, 256),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.Linear(256, CFG.num_classes)
    )
    model.load_state_dict(torch.load('models/best_model_512_padding.pt', map_location=CFG.device))
    model.to(CFG.device)
    model.eval()




    # âœ… ç­›é€‰æ¯ç±»ä¸€ä¸ªæ–‡ä»¶ç”¨äºæ¨ç†
    selected_lines = []
    seen_prefix = set()
    with open(CFG.val_txt, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or "," not in line:
                continue
            path, label = line.split(",", 1)
            filename = os.path.basename(path)

            # âœ… åªä¿ç•™ xxx.jpg æˆ– xxx_1.jpg æ–‡ä»¶
            if "_" in filename:
                name_part = filename.split(".")[0]
                suffix = name_part.split("_")[-1]
                if suffix != "1":
                    continue
            elif "_" in filename:
                continue  # æœ‰ä¸‹åˆ’çº¿ä½†ä¸æ˜¯ _1
            # âœ… æ·»åŠ è¿›ç­›é€‰
            selected_lines.append((path, label))

    print(f"\nğŸ“‚ å…±é€‰æ‹© {len(selected_lines)} å¼ å›¾ç‰‡ç”¨äºæ¨ç†")

    # æ„å»ºæ•°æ®é›†
    class InferenceDataset(torch.utils.data.Dataset):
        def __init__(self, selected_data, transform):
            self.data = selected_data
            self.transform = transform

        def __len__(self):
            return len(self.data)

        def __getitem__(self, idx):
            path, label = self.data[idx]
            image = Image.open(path).convert("RGB")
            image = self.transform(image)
            label_idx = name2idx[label]  # âœ… å°† label æ˜ å°„ä¸ºæ•´æ•°ç´¢å¼•
            return image, label_idx, os.path.basename(path)

    dataset = InferenceDataset(selected_lines, transform=transform)
    dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=0)

    # æ¨ç†
    all_preds, all_labels, all_names = [], [], []
    batch_times = []  # âœ… ç”¨äºè®°å½•æ¯ä¸ª batch çš„è€—æ—¶
    with torch.no_grad():
        for batch_idx, (imgs, labels, names) in enumerate(dataloader):
            start_time = time.time()  # âœ… å¼€å§‹è®¡æ—¶

            imgs = imgs.to(CFG.device)
            outputs = model(imgs)
            _, preds = torch.max(outputs, 1)

            batch_time = time.time() - start_time  # âœ… å½“å‰ batch è€—æ—¶
            batch_times.append(batch_time)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())
            all_names.extend(names)

            print(f"ğŸ” Batch {batch_idx + 1}: æ¨ç† {len(imgs)} å¼ å›¾ï¼Œè€—æ—¶ {batch_time:.4f} ç§’")

    # è§£ç é¢„æµ‹å€¼
    decoded_preds = [idx2name[p] for p in all_preds]
    decoded_labels = [idx2name[l] for l in all_labels]

    # è®¡ç®—æŒ‡æ ‡
    acc = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='macro')
    print(f"\nâœ… Accuracy: {acc:.4f} | F1-score (macro): {f1:.4f}\n")

    print("ğŸ“Š 512*512 åˆ†ç±»æŠ¥å‘Šï¼š")
    print(classification_report(all_labels, all_preds, target_names=list(label_map.keys()), digits=4))

    output_path = "test_final_inference_all_on_pdfonly.csv"
    with open(output_path, "w", newline='', encoding="utf-8") as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["filename", "predicted", "true", "correct"])
        for name, pred, true in zip(all_names, decoded_preds, decoded_labels):
            correct = "1" if pred == true else "0"
            writer.writerow([name, pred, true, correct])
    print(f"\nâœ… æ¨ç†ç»“æœå·²ä¿å­˜è‡³ CSV æ–‡ä»¶ï¼š{output_path}")


# âœ… ä¸»å‡½æ•°ä¿æŠ¤ï¼ˆå…¼å®¹ Windows å¤šè¿›ç¨‹ï¼‰
if __name__ == '__main__':
    from multiprocessing import freeze_support
    freeze_support()
    run_inference()
